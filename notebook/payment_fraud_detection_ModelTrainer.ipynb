{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Payment Fraud Detection</h2>\n",
    "<h3>Feature Engineering and Model Training</h3>\n",
    "<h4>Author: Akshay Pandurang Paunikar</h4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\iNeuron\\Projects\\Payment_Fraud_Detection\\notebook\\datasets\n"
     ]
    }
   ],
   "source": [
    "# set the working directory\n",
    "import io\n",
    "%cd \"E:\\iNeuron\\Projects\\Payment_Fraud_Detection\\notebook\\datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AccountAgeDays</th>\n",
       "      <th>NumItems</th>\n",
       "      <th>localTime</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>PaymentMethodAgeDays</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>4.75</td>\n",
       "      <td>paypal</td>\n",
       "      <td>28.2</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>725</td>\n",
       "      <td>1</td>\n",
       "      <td>4.74</td>\n",
       "      <td>storecredit</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>845</td>\n",
       "      <td>1</td>\n",
       "      <td>4.92</td>\n",
       "      <td>creditcard</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>503</td>\n",
       "      <td>1</td>\n",
       "      <td>4.89</td>\n",
       "      <td>creditcard</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>5.04</td>\n",
       "      <td>creditcard</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AccountAgeDays  NumItems  localTime PaymentMethod  PaymentMethodAgeDays  \\\n",
       "0              29         1       4.75        paypal                  28.2   \n",
       "1             725         1       4.74   storecredit                   0.0   \n",
       "2             845         1       4.92    creditcard                   0.0   \n",
       "3             503         1       4.89    creditcard                   0.0   \n",
       "4            2000         1       5.04    creditcard                   0.0   \n",
       "\n",
       "  Label  \n",
       "0  Good  \n",
       "1  Good  \n",
       "2  Good  \n",
       "3  Good  \n",
       "4  Good  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data\n",
    "data = pd.read_csv(\"final_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into independent features and dependent target variable\n",
    "X = data.drop(['Label'], axis=1)\n",
    "y = data['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of Label Encoder, One Hot Encode, Standard Scaler\n",
    "le = LabelEncoder()\n",
    "one_hot = OneHotEncoder()\n",
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Columns:\n",
      " Index(['AccountAgeDays', 'NumItems', 'localTime', 'PaymentMethodAgeDays'], dtype='object')\n",
      "Categorical Columns:\n",
      " Index(['PaymentMethod'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# numerical columns and categorical columns\n",
    "num_features = X.select_dtypes(exclude=\"object\").columns\n",
    "cat_features = X.select_dtypes(include=\"object\").columns\n",
    "\n",
    "print(\"Numerical Columns:\\n\", num_features)\n",
    "print(\"Categorical Columns:\\n\", cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipelines for categorical and numerical data\n",
    "num_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"Scaler\", StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "cat_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"one hot\", OneHotEncoder()),\n",
    "        (\"Scaler\", StandardScaler(with_mean=False))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating preprocessor object\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num_pipeline\", num_pipeline, num_features),\n",
    "    (\"cat_pipeline\", cat_pipeline, cat_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying preprocesing object to features\n",
    "X = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encode target variable\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (21329, 7)\n",
      "y_train: (21329,)\n",
      "X_test: (9142, 7)\n",
      "y_test: (9142,)\n"
     ]
    }
   ],
   "source": [
    "# divide the data into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=333)\n",
    "\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\iNeuron\\Projects\\Payment_Fraud_Detection\\notebook\n"
     ]
    }
   ],
   "source": [
    "# set the working directory\n",
    "import io\n",
    "%cd \"E:\\iNeuron\\Projects\\Payment_Fraud_Detection\\notebook\\\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Evaluate Function to give all metrics after model Training\n",
    "def evaluate_model(true, predicted):\n",
    "    accuracy = accuracy_score(true, predicted)\n",
    "    confusionmatrix = confusion_matrix(true, predicted)    \n",
    "    classificationreport = classification_report(true, predicted)\n",
    "    return accuracy, confusionmatrix, classificationreport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Model performance for Training set\n",
      "**Accuracy Score: 0.9950302405176051\n",
      "**Confusion Matrix: \n",
      " [[    0   105]\n",
      " [    1 21223]]\n",
      "**Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       105\n",
      "           1       1.00      1.00      1.00     21224\n",
      "\n",
      "    accuracy                           1.00     21329\n",
      "   macro avg       0.50      0.50      0.50     21329\n",
      "weighted avg       0.99      1.00      0.99     21329\n",
      "\n",
      "-----------------------------------\n",
      "Model performance for Test set\n",
      "**Accuracy Score: 0.9945307372566178\n",
      "**Confusion Matrix: \n",
      " [[   0   49]\n",
      " [   1 9092]]\n",
      "**Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        49\n",
      "           1       0.99      1.00      1.00      9093\n",
      "\n",
      "    accuracy                           0.99      9142\n",
      "   macro avg       0.50      0.50      0.50      9142\n",
      "weighted avg       0.99      0.99      0.99      9142\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree Classifier\n",
      "Model performance for Training set\n",
      "**Accuracy Score: 1.0\n",
      "**Confusion Matrix: \n",
      " [[  105     0]\n",
      " [    0 21224]]\n",
      "**Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       105\n",
      "           1       1.00      1.00      1.00     21224\n",
      "\n",
      "    accuracy                           1.00     21329\n",
      "   macro avg       1.00      1.00      1.00     21329\n",
      "weighted avg       1.00      1.00      1.00     21329\n",
      "\n",
      "-----------------------------------\n",
      "Model performance for Test set\n",
      "**Accuracy Score: 1.0\n",
      "**Confusion Matrix: \n",
      " [[  49    0]\n",
      " [   0 9093]]\n",
      "**Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        49\n",
      "           1       1.00      1.00      1.00      9093\n",
      "\n",
      "    accuracy                           1.00      9142\n",
      "   macro avg       1.00      1.00      1.00      9142\n",
      "weighted avg       1.00      1.00      1.00      9142\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest Classifier\n",
      "Model performance for Training set\n",
      "**Accuracy Score: 1.0\n",
      "**Confusion Matrix: \n",
      " [[  105     0]\n",
      " [    0 21224]]\n",
      "**Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       105\n",
      "           1       1.00      1.00      1.00     21224\n",
      "\n",
      "    accuracy                           1.00     21329\n",
      "   macro avg       1.00      1.00      1.00     21329\n",
      "weighted avg       1.00      1.00      1.00     21329\n",
      "\n",
      "-----------------------------------\n",
      "Model performance for Test set\n",
      "**Accuracy Score: 1.0\n",
      "**Confusion Matrix: \n",
      " [[  49    0]\n",
      " [   0 9093]]\n",
      "**Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        49\n",
      "           1       1.00      1.00      1.00      9093\n",
      "\n",
      "    accuracy                           1.00      9142\n",
      "   macro avg       1.00      1.00      1.00      9142\n",
      "weighted avg       1.00      1.00      1.00      9142\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boosting Classifier\n",
      "Model performance for Training set\n",
      "**Accuracy Score: 1.0\n",
      "**Confusion Matrix: \n",
      " [[  105     0]\n",
      " [    0 21224]]\n",
      "**Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       105\n",
      "           1       1.00      1.00      1.00     21224\n",
      "\n",
      "    accuracy                           1.00     21329\n",
      "   macro avg       1.00      1.00      1.00     21329\n",
      "weighted avg       1.00      1.00      1.00     21329\n",
      "\n",
      "-----------------------------------\n",
      "Model performance for Test set\n",
      "**Accuracy Score: 1.0\n",
      "**Confusion Matrix: \n",
      " [[  49    0]\n",
      " [   0 9093]]\n",
      "**Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        49\n",
      "           1       1.00      1.00      1.00      9093\n",
      "\n",
      "    accuracy                           1.00      9142\n",
      "   macro avg       1.00      1.00      1.00      9142\n",
      "weighted avg       1.00      1.00      1.00      9142\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoost Classifier\n",
      "Model performance for Training set\n",
      "**Accuracy Score: 1.0\n",
      "**Confusion Matrix: \n",
      " [[  105     0]\n",
      " [    0 21224]]\n",
      "**Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       105\n",
      "           1       1.00      1.00      1.00     21224\n",
      "\n",
      "    accuracy                           1.00     21329\n",
      "   macro avg       1.00      1.00      1.00     21329\n",
      "weighted avg       1.00      1.00      1.00     21329\n",
      "\n",
      "-----------------------------------\n",
      "Model performance for Test set\n",
      "**Accuracy Score: 1.0\n",
      "**Confusion Matrix: \n",
      " [[  49    0]\n",
      " [   0 9093]]\n",
      "**Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        49\n",
      "           1       1.00      1.00      1.00      9093\n",
      "\n",
      "    accuracy                           1.00      9142\n",
      "   macro avg       1.00      1.00      1.00      9142\n",
      "weighted avg       1.00      1.00      1.00      9142\n",
      "\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\anaconda\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Classifier\n",
      "Model performance for Training set\n",
      "**Accuracy Score: 0.995077125041024\n",
      "**Confusion Matrix: \n",
      " [[    0   105]\n",
      " [    0 21224]]\n",
      "**Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       105\n",
      "           1       1.00      1.00      1.00     21224\n",
      "\n",
      "    accuracy                           1.00     21329\n",
      "   macro avg       0.50      0.50      0.50     21329\n",
      "weighted avg       0.99      1.00      0.99     21329\n",
      "\n",
      "-----------------------------------\n",
      "Model performance for Test set\n",
      "**Accuracy Score: 0.9946401225114855\n",
      "**Confusion Matrix: \n",
      " [[   0   49]\n",
      " [   0 9093]]\n",
      "**Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        49\n",
      "           1       0.99      1.00      1.00      9093\n",
      "\n",
      "    accuracy                           0.99      9142\n",
      "   macro avg       0.50      0.50      0.50      9142\n",
      "weighted avg       0.99      0.99      0.99      9142\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "Gaussian Naive Bayes\n",
      "Model performance for Training set\n",
      "**Accuracy Score: 0.9999062309531623\n",
      "**Confusion Matrix: \n",
      " [[  103     2]\n",
      " [    0 21224]]\n",
      "**Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       105\n",
      "           1       1.00      1.00      1.00     21224\n",
      "\n",
      "    accuracy                           1.00     21329\n",
      "   macro avg       1.00      0.99      1.00     21329\n",
      "weighted avg       1.00      1.00      1.00     21329\n",
      "\n",
      "-----------------------------------\n",
      "Model performance for Test set\n",
      "**Accuracy Score: 1.0\n",
      "**Confusion Matrix: \n",
      " [[  49    0]\n",
      " [   0 9093]]\n",
      "**Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        49\n",
      "           1       1.00      1.00      1.00      9093\n",
      "\n",
      "    accuracy                           1.00      9142\n",
      "   macro avg       1.00      1.00      1.00      9142\n",
      "weighted avg       1.00      1.00      1.00      9142\n",
      "\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\machinelearning\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "d:\\anaconda\\envs\\machinelearning\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Neighbors Classifier\n",
      "Model performance for Training set\n",
      "**Accuracy Score: 0.9958741619391439\n",
      "**Confusion Matrix: \n",
      " [[   25    80]\n",
      " [    8 21216]]\n",
      "**Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.24      0.36       105\n",
      "           1       1.00      1.00      1.00     21224\n",
      "\n",
      "    accuracy                           1.00     21329\n",
      "   macro avg       0.88      0.62      0.68     21329\n",
      "weighted avg       1.00      1.00      0.99     21329\n",
      "\n",
      "-----------------------------------\n",
      "Model performance for Test set\n",
      "**Accuracy Score: 0.9946401225114855\n",
      "**Confusion Matrix: \n",
      " [[   7   42]\n",
      " [   7 9086]]\n",
      "**Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.14      0.22        49\n",
      "           1       1.00      1.00      1.00      9093\n",
      "\n",
      "    accuracy                           0.99      9142\n",
      "   macro avg       0.75      0.57      0.61      9142\n",
      "weighted avg       0.99      0.99      0.99      9142\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "CatBoost Classifier\n",
      "Model performance for Training set\n",
      "**Accuracy Score: 1.0\n",
      "**Confusion Matrix: \n",
      " [[  105     0]\n",
      " [    0 21224]]\n",
      "**Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       105\n",
      "           1       1.00      1.00      1.00     21224\n",
      "\n",
      "    accuracy                           1.00     21329\n",
      "   macro avg       1.00      1.00      1.00     21329\n",
      "weighted avg       1.00      1.00      1.00     21329\n",
      "\n",
      "-----------------------------------\n",
      "Model performance for Test set\n",
      "**Accuracy Score: 1.0\n",
      "**Confusion Matrix: \n",
      " [[  49    0]\n",
      " [   0 9093]]\n",
      "**Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        49\n",
      "           1       1.00      1.00      1.00      9093\n",
      "\n",
      "    accuracy                           1.00      9142\n",
      "   macro avg       1.00      1.00      1.00      9142\n",
      "weighted avg       1.00      1.00      1.00      9142\n",
      "\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBoost Classifier\n",
      "Model performance for Training set\n",
      "**Accuracy Score: 1.0\n",
      "**Confusion Matrix: \n",
      " [[  105     0]\n",
      " [    0 21224]]\n",
      "**Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       105\n",
      "           1       1.00      1.00      1.00     21224\n",
      "\n",
      "    accuracy                           1.00     21329\n",
      "   macro avg       1.00      1.00      1.00     21329\n",
      "weighted avg       1.00      1.00      1.00     21329\n",
      "\n",
      "-----------------------------------\n",
      "Model performance for Test set\n",
      "**Accuracy Score: 1.0\n",
      "**Confusion Matrix: \n",
      " [[  49    0]\n",
      " [   0 9093]]\n",
      "**Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        49\n",
      "           1       1.00      1.00      1.00      9093\n",
      "\n",
      "    accuracy                           1.00      9142\n",
      "   macro avg       1.00      1.00      1.00      9142\n",
      "weighted avg       1.00      1.00      1.00      9142\n",
      "\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Decision Tree Classifier': DecisionTreeClassifier(),\n",
    "    'Random Forest Classifier': RandomForestClassifier(),\n",
    "    'Gradient Boosting Classifier': GradientBoostingClassifier(),\n",
    "    'AdaBoost Classifier': AdaBoostClassifier(),\n",
    "    'Support Vector Classifier': SVC(),\n",
    "    'Gaussian Naive Bayes': GaussianNB(),\n",
    "    'K-Neighbors Classifier': KNeighborsClassifier(),\n",
    "    'CatBoost Classifier': CatBoostClassifier(verbose=False),\n",
    "    'XGBoost Classifier': XGBClassifier()\n",
    "}\n",
    "\n",
    "model_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate Train and Test dataset\n",
    "    train_accuracy, train_confusionmatrix, train_classificationreport = evaluate_model(y_train,y_train_pred)\n",
    "\n",
    "    test_accuracy, test_confusionmatrix, test_classificationreport = evaluate_model(y_test, y_test_pred)\n",
    "        \n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"**Accuracy Score:\", train_accuracy)\n",
    "    print(\"**Confusion Matrix: \\n\", train_confusionmatrix)\n",
    "    print(\"**Classification Report: \\n\", train_classificationreport)\n",
    "\n",
    "    print('-'*35)\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(\"**Accuracy Score:\", test_accuracy)\n",
    "    print(\"**Confusion Matrix: \\n\", test_confusionmatrix)\n",
    "    print(\"**Classification Report: \\n\", test_classificationreport)\n",
    "    \n",
    "    accuracy_list.append(test_accuracy)\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CatBoost Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Support Vector Classifier</td>\n",
       "      <td>0.994640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>K-Neighbors Classifier</td>\n",
       "      <td>0.994640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.994531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model Name  Accuracy Score\n",
       "1      Decision Tree Classifier        1.000000\n",
       "2      Random Forest Classifier        1.000000\n",
       "3  Gradient Boosting Classifier        1.000000\n",
       "4           AdaBoost Classifier        1.000000\n",
       "6          Gaussian Naive Bayes        1.000000\n",
       "8           CatBoost Classifier        1.000000\n",
       "9            XGBoost Classifier        1.000000\n",
       "5     Support Vector Classifier        0.994640\n",
       "7        K-Neighbors Classifier        0.994640\n",
       "0           Logistic Regression        0.994531"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results\n",
    "pd.DataFrame(list(zip(model_list, accuracy_list)), columns=['Model Name', 'Accuracy Score']).sort_values(by=[\"Accuracy Score\"],\n",
    "                                                                                                         ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we wil use XGBoost Classifier\n",
    "model_xgboost = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit training data\n",
    "model_xgboost.fit(X_train, y_train)\n",
    "model_xgboost.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on test data\n",
    "predictions = model_xgboost.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 100.0\n",
      "Confusion Matrix:\n",
      " [[  49    0]\n",
      " [   0 9093]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        49\n",
      "           1       1.00      1.00      1.00      9093\n",
      "\n",
      "    accuracy                           1.00      9142\n",
      "   macro avg       1.00      1.00      1.00      9142\n",
      "weighted avg       1.00      1.00      1.00      9142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# performance metrics\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, predictions).round(4)*100)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, predictions))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Value</th>\n",
       "      <th>Predicted Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9137</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9138</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9139</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9140</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9141</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9142 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual Value  Predicted Value\n",
       "0                1                1\n",
       "1                1                1\n",
       "2                1                1\n",
       "3                1                1\n",
       "4                1                1\n",
       "...            ...              ...\n",
       "9137             1                1\n",
       "9138             1                1\n",
       "9139             1                1\n",
       "9140             1                1\n",
       "9141             1                1\n",
       "\n",
       "[9142 rows x 2 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Difference between Actual and Predicted Values\n",
    "pred_df=pd.DataFrame({'Actual Value':y_test,'Predicted Value':predictions})\n",
    "pred_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
